# LAB P1-01 â€” Scaled Dot-Product Attention (From Scratch)

ImplementaÃ§Ã£o manual do mecanismo de **Self-Attention** conforme o paper  
_"Attention Is All You Need"_ (Vaswani et al., 2017).

## EquaÃ§Ã£o Implementada

```
Attention(Q, K, V) = softmax( QKáµ€ / âˆšd_k ) Â· V
```

---

## Como Rodar

```bash
# 1. Instalar dependÃªncias
pip install numpy matplotlib

# 2. Rodar os testes
python test_attention.py

# 3. Gerar o heatmap de pesos de atenÃ§Ã£o
python heatmap.py
```

---

## Como a NormalizaÃ§Ã£o âˆšd_k foi Aplicada

O produto escalar `QKáµ€` cresce em magnitude Ã  medida que `d_k` aumenta,  
empurrando o softmax para regiÃµes de gradiente muito pequeno (vanishing gradients).

Para estabilizar o treinamento, **dividimos os scores por `âˆšd_k`** antes do softmax:

```python
scaled_scores = (Q @ K.T) / np.sqrt(self.d_k)
attention_weights = softmax(scaled_scores)
```

Isso mantÃ©m a variÃ¢ncia dos scores prÃ³xima de 1, independente da dimensÃ£o escolhida.

---

## Exemplo de Input e Output Esperado

```python
# Input: 3 tokens, d_model=3 (matriz identidade)
X = np.eye(3)

# Output esperado (aproximado, depende dos pesos W_q, W_k, W_v)
# Attention Weights â‰ˆ distribuiÃ§Ã£o uniforme (~0.333 por cÃ©lula)
# porque tokens da identidade sÃ£o ortogonais entre si
```

| Token   | Peso p/ Token 1 | Peso p/ Token 2 | Peso p/ Token 3 |
| ------- | --------------- | --------------- | --------------- |
| Token 1 | 0.334           | 0.334           | 0.333           |
| Token 2 | 0.331           | 0.332           | 0.337           |
| Token 3 | 0.333           | 0.333           | 0.334           |

_Soma de cada linha = 1.0 (propriedade do softmax)_

---

## Testes de ValidaÃ§Ã£o

O arquivo `test_attention.py` contÃ©m **6 casos de teste**:

1. **Shapes de saÃ­da** â€” verifica se `output.shape == (seq_len, d_v)` e `attention_weights.shape == (seq_len, seq_len)`
2. **Pesos somam 1 por linha** â€” valida a propriedade fundamental do softmax
3. **Pesos em [0, 1]** â€” garante que nenhum peso estÃ¡ fora do intervalo vÃ¡lido
4. **Exemplo numÃ©rico determinÃ­stico** â€” forÃ§a `W_q = W_k = W_v = I` e verifica o cÃ¡lculo passo a passo contra resultado manual
5. **Scaling evita colapso do softmax** â€” compara a entropia das distribuiÃ§Ãµes com e sem `âˆšd_k`, confirmando que o scaling suaviza os pesos
6. **Softmax numericamente estÃ¡vel** â€” testa com scores da ordem de 1000 para garantir ausÃªncia de `NaN` ou `Inf`

---

## VisualizaÃ§Ã£o (heatmap.py)

O script `heatmap.py` gera dois painÃ©is lado a lado para uma sequÃªncia de 5 tokens (`"O", "gato", "sentou", "no", "tapete"`) com `d_model=16`, `d_k=8`, `d_v=8`:

- **Painel esquerdo** â€” Attention Weights apÃ³s o softmax (colormap `viridis`, escala [0, 1])
- **Painel direito** â€” Scaled Scores brutos `QKáµ€ / âˆšd_k` antes do softmax (colormap `coolwarm`)

O heatmap Ã© salvo automaticamente como `attention_heatmap.png`.

---

## Estrutura do RepositÃ³rio

```
.
â”œâ”€â”€ attention.py          # ImplementaÃ§Ã£o da classe ScaledDotProductAttention
â”œâ”€â”€ test_attention.py     # Scripts de teste com 6 casos de validaÃ§Ã£o
â”œâ”€â”€ heatmap.py            # VisualizaÃ§Ã£o dos pesos via heatmap (matplotlib)
â”œâ”€â”€ attention_heatmap.png # Heatmap gerado
â”œâ”€â”€ requirements.txt      # DependÃªncias: numpy>=1.24, matplotlib>=3.7
â””â”€â”€ README.md             # Esta documentaÃ§Ã£o


---

## DependÃªncias

```

numpy>=1.24
matplotlib>=3.7

```

---

> ğŸ“„ *Este README foi gerado com auxÃ­lio de InteligÃªncia Artificial (Claude, Anthropic) e revisado para refletir com precisÃ£o o conteÃºdo dos arquivos do projeto.*
```
